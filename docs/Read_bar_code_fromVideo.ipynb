{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3b22a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install opencv\n",
    "# %pip install opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3bb1f67-0c65-44a6-8edb-3d540f5e0ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/henrikvendelbo/.zshenv:.:1: no such file or directory: /Users/henrikvendelbo/.cargo/env\n",
      "Collecting pyzbar\n",
      "  Downloading pyzbar-0.1.9-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Downloading pyzbar-0.1.9-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pyzbar\n",
      "Successfully installed pyzbar-0.1.9\n",
      "/Users/henrikvendelbo/.zshenv:.:1: no such file or directory: /Users/henrikvendelbo/.cargo/env\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.49-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (1.26.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (6.0.0)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from ultralytics) (2.2.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.3.49-py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m898.7/898.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, ultralytics-thop, seaborn, ultralytics\n",
      "Successfully installed py-cpuinfo-9.0.0 seaborn-0.13.2 ultralytics-8.3.49 ultralytics-thop-2.0.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/henrikvendelbo/.zshenv:.:1: no such file or directory: /Users/henrikvendelbo/.cargo/env\n",
      "Collecting zxing\n",
      "  Downloading zxing-1.0.3.tar.gz (689 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.6/689.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: zxing\n",
      "  Building wheel for zxing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for zxing: filename=zxing-1.0.3-py3-none-any.whl size=684453 sha256=aaed2ed90f34ce93921a8676615290580691052485d1c2b62ffdde2327b6e21f\n",
      "  Stored in directory: /Users/henrikvendelbo/Library/Caches/pip/wheels/99/34/5a/0dcc3878d8c58ac613fed5b14aa0e6b9794b28d5456e442493\n",
      "Successfully built zxing\n",
      "Installing collected packages: zxing\n",
      "Successfully installed zxing-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/henrikvendelbo/.zshenv:.:1: no such file or directory: /Users/henrikvendelbo/.cargo/env\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyzbar\n",
    "%pip install ultralytics\n",
    "%pip install zxing\n",
    "%pip install cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d44b8",
   "metadata": {},
   "source": [
    "## video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a7bec41-d33a-4440-bfc0-5f393322e0d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'barcode_scanner.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m,image)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Initialize the trained YOLO model\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m model_trained \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbarcode_scanner.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Specify the path to the video file\u001b[39;00m\n\u001b[1;32m     61\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_2.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/ultralytics/models/yolo/model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/ultralytics/engine/model.py:146\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/ultralytics/engine/model.py:289\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    286\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/ultralytics/nn/tasks.py:910\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    909\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 910\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/ultralytics/nn/tasks.py:837\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m    835\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 837\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/ultralytics/utils/patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/torch/serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/torch/serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/lib/python3.11/site-packages/torch/serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'barcode_scanner.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Specify the path to the video file\n",
    "\n",
    "import cv2\n",
    "from zxing import BarCodeReader\n",
    "import tempfile\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "def is_rectangle_contained(outer_rect, inner_rect):\n",
    "\n",
    "    outer_x1, outer_y1, outer_x2, outer_y2 = outer_rect\n",
    "    inner_x1, inner_y1, inner_x2, inner_y2 = inner_rect\n",
    "    \n",
    "    return inner_x1 >= outer_x1 and inner_y1 >= outer_y1 and inner_x2 <= outer_x2 and inner_y2 <= outer_y2\n",
    "\n",
    "def print_rectangle_contained(results,results2):\n",
    "    image = results[0].plot() & results2[0].plot()\n",
    "    flag=0\n",
    "    color1 = (0, 255, 0)  # Green color\n",
    "    color2 = (255, 0, 0)\n",
    "    thickness =2\n",
    "    reader = BarCodeReader()\n",
    "    for box in zip(results[0].boxes.xyxy,results[0].boxes.conf):\n",
    "        flag=0\n",
    "        for box2 in zip(results2[0].boxes.xywh,results2[0].boxes.conf):\n",
    "            if(is_rectangle_contained(np.array(box[0]),np.array(box2[0]))):\n",
    "                x1,y1,x2,y2 =np.array(box[0]) \n",
    "                rect1 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect1[0],rect1[1], color1, thickness)\n",
    "                x3,y3,width3,height3= np.array(box2[0])\n",
    "                x,y,width,height = int(x3 - (width3)/2),int(y3 - (height3)/2),int(width3),int(height3)\n",
    "                region_img = image[y:y+height, x:x+width]\n",
    "                region_img_gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "                # Save the cropped region as a temporary file\n",
    "                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "                  #  print(temp_file.name)\n",
    "                    temp_file_path = temp_file.name\n",
    "                    cv2.imwrite(temp_file_path, region_img_gray)\n",
    "               # gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "               # buf = np.ascontiguousarray(gray).tobytes()\n",
    "                \n",
    "                barcode = reader.decode(temp_file_path)\n",
    "                \n",
    "                \n",
    "                print('box :',np.array(box[0]),'conf:',box[1],'barcode :',np.array(box2[0]),'conf:',box2[1],'value : ',barcode.raw)\n",
    "                flag=1\n",
    "                \n",
    "            \n",
    "        if flag==0:\n",
    "                x1,y1,x2,y2 =np.array(box[0]) \n",
    "                rect2 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect2[0],rect2[1], color2, thickness)\n",
    "                print('box :',np.array(box[0]),'does not contain barcode')\n",
    "  \n",
    "    cv2.imshow('image',image)\n",
    "    \n",
    "# Initialize the trained YOLO model\n",
    "model_trained = YOLO('barcode_scanner.pt')\n",
    "\n",
    "# Specify the path to the video file\n",
    "video_path = 'video_2.mp4'\n",
    "\n",
    "# Open the video file for reading\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    # Loop to read and process each frame\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        # Check if the frame was read successfully\n",
    "        if not ret:\n",
    "            print(\"End of video or unable to read frame.\")\n",
    "            break\n",
    "        if frame_count % 20 != 0:\n",
    "            continue   \n",
    "       # frame_resized = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5) \n",
    "        image = frame #frame_resized #cv2.imread(frame)\n",
    "        original_height, original_width, _ = image.shape\n",
    "        \n",
    "        model_trained = YOLO('best.pt')\n",
    "        barcode_scanner_model = YOLO('barcode_scanner.pt')\n",
    "        \n",
    "        results = model_trained.predict(frame,imgsz=128)\n",
    "        results2 = barcode_scanner_model.predict(frame,imgsz=(original_height, original_width))\n",
    "        print_rectangle_contained(results,results2)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb83d34",
   "metadata": {},
   "source": [
    "## open camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "206336d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 291.1ms\n",
      "Speed: 6.3ms preprocess, 291.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 37.6ms\n",
      "Speed: 0.8ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 177.1ms\n",
      "Speed: 2.2ms preprocess, 177.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.1ms\n",
      "Speed: 2.1ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 163.6ms\n",
      "Speed: 2.5ms preprocess, 163.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.5ms\n",
      "Speed: 1.3ms preprocess, 23.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 170.2ms\n",
      "Speed: 2.7ms preprocess, 170.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 161.4ms\n",
      "Speed: 2.2ms preprocess, 161.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.6ms\n",
      "Speed: 0.6ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 157.9ms\n",
      "Speed: 2.3ms preprocess, 157.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.3ms\n",
      "Speed: 1.2ms preprocess, 24.3ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 151.7ms\n",
      "Speed: 2.4ms preprocess, 151.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 21.0ms\n",
      "Speed: 1.2ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 156.2ms\n",
      "Speed: 2.6ms preprocess, 156.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 166.4ms\n",
      "Speed: 3.4ms preprocess, 166.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 21.1ms\n",
      "Speed: 1.0ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 150.2ms\n",
      "Speed: 2.6ms preprocess, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.0ms\n",
      "Speed: 1.0ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 166.2ms\n",
      "Speed: 2.8ms preprocess, 166.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.1ms\n",
      "Speed: 1.0ms preprocess, 24.1ms inference, 0.9ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 149.4ms\n",
      "Speed: 2.8ms preprocess, 149.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 21.8ms\n",
      "Speed: 1.0ms preprocess, 21.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 153.3ms\n",
      "Speed: 1.9ms preprocess, 153.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.2ms\n",
      "Speed: 4.1ms preprocess, 24.2ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 168.9ms\n",
      "Speed: 3.3ms preprocess, 168.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 20.9ms\n",
      "Speed: 1.0ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 165.9ms\n",
      "Speed: 2.4ms preprocess, 165.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 30.7ms\n",
      "Speed: 1.9ms preprocess, 30.7ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 176.4ms\n",
      "Speed: 2.5ms preprocess, 176.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 29.5ms\n",
      "Speed: 1.3ms preprocess, 29.5ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 173.8ms\n",
      "Speed: 3.8ms preprocess, 173.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 45.6ms\n",
      "Speed: 7.4ms preprocess, 45.6ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 200.4ms\n",
      "Speed: 3.1ms preprocess, 200.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 37.7ms\n",
      "Speed: 1.3ms preprocess, 37.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 146.6ms\n",
      "Speed: 2.2ms preprocess, 146.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 19.5ms\n",
      "Speed: 1.0ms preprocess, 19.5ms inference, 0.7ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 142.9ms\n",
      "Speed: 2.0ms preprocess, 142.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.5ms\n",
      "Speed: 1.4ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 149.1ms\n",
      "Speed: 2.3ms preprocess, 149.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.1ms\n",
      "Speed: 1.4ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 141.3ms\n",
      "Speed: 4.3ms preprocess, 141.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 148.9ms\n",
      "Speed: 3.1ms preprocess, 148.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 0.4ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 148.5ms\n",
      "Speed: 2.4ms preprocess, 148.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.5ms\n",
      "Speed: 1.0ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 149.6ms\n",
      "Speed: 5.3ms preprocess, 149.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 30.7ms\n",
      "Speed: 1.0ms preprocess, 30.7ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 153.9ms\n",
      "Speed: 2.3ms preprocess, 153.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.0ms\n",
      "Speed: 1.1ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 136.9ms\n",
      "Speed: 2.7ms preprocess, 136.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.6ms\n",
      "Speed: 1.1ms preprocess, 24.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 140.1ms\n",
      "Speed: 2.6ms preprocess, 140.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 31.0ms\n",
      "Speed: 1.0ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 145.8ms\n",
      "Speed: 2.3ms preprocess, 145.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 2 class_0s, 22.5ms\n",
      "Speed: 0.8ms preprocess, 22.5ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 139.7ms\n",
      "Speed: 1.8ms preprocess, 139.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     398.47      340.22      612.68      409.36] conf: tensor(0.4729) barcode: [     510.43      375.36      208.49      72.246] conf: tensor(0.9353) value: \n",
      "box: [      119.9      170.29      328.56      232.59] conf: tensor(0.3574) barcode: [     222.46      203.93      206.28      62.309] conf: tensor(0.9529) value: Hii Sir\n",
      "box: [      119.9      170.29      328.56      232.59] conf: tensor(0.3574) barcode: [     227.66      383.05      192.65      68.337] conf: tensor(0.9527) value: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [      119.9      170.29      328.56      232.59] conf: tensor(0.3574) barcode: [     481.84      198.48       207.4      56.504] conf: tensor(0.9427) value: \n",
      "box: [      119.9      170.29      328.56      232.59] conf: tensor(0.3574) barcode: [     510.43      375.36      208.49      72.246] conf: tensor(0.9353) value: \n",
      "\n",
      "0: 96x128 2 class_0s, 21.4ms\n",
      "Speed: 2.0ms preprocess, 21.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 154.6ms\n",
      "Speed: 2.7ms preprocess, 154.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     75.123      351.81      301.77       429.8] conf: tensor(0.7471) barcode: [     518.65      384.61      242.71      85.957] conf: tensor(0.9599) value: 1234509876\n",
      "box: [     75.123      351.81      301.77       429.8] conf: tensor(0.7471) barcode: [     188.65      392.67      224.97      77.573] conf: tensor(0.9582) value: \n",
      "box: [     396.13      340.81      639.49       428.3] conf: tensor(0.4500) barcode: [     518.65      384.61      242.71      85.957] conf: tensor(0.9599) value: 1234509876\n",
      "\n",
      "0: 96x128 1 class_0, 29.7ms\n",
      "Speed: 0.0ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 146.9ms\n",
      "Speed: 2.6ms preprocess, 146.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     78.633      350.79      295.48      426.78] conf: tensor(0.8292) barcode: [      187.8      390.33      218.06          76] conf: tensor(0.9551) value: \n",
      "box: [     78.633      350.79      295.48      426.78] conf: tensor(0.8292) barcode: [     511.58      382.66      241.84      84.559] conf: tensor(0.9459) value: 1234509876\n",
      "\n",
      "0: 96x128 2 class_0s, 27.9ms\n",
      "Speed: 1.0ms preprocess, 27.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 153.9ms\n",
      "Speed: 4.0ms preprocess, 153.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     107.29      173.89      354.18      260.22] conf: tensor(0.3428) barcode: [     230.62      215.19       245.7      85.544] conf: tensor(0.9468) value: Hii Sir\n",
      "box: [     107.29      173.89      354.18      260.22] conf: tensor(0.3428) barcode: [      524.1      195.42      231.17      77.993] conf: tensor(0.9465) value: \n",
      "box: [     107.29      173.89      354.18      260.22] conf: tensor(0.3428) barcode: [      252.9      420.68      224.57      83.477] conf: tensor(0.9452) value: \n",
      "box: [     107.29      173.89      354.18      260.22] conf: tensor(0.3428) barcode: [     545.75      393.56      187.57      96.905] conf: tensor(0.8907) value: \n",
      "box: [     449.63      353.12         640      438.47] conf: tensor(0.3147) barcode: [     545.75      393.56      187.57      96.905] conf: tensor(0.8907) value: \n",
      "\n",
      "0: 96x128 2 class_0s, 22.6ms\n",
      "Speed: 1.0ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 141.2ms\n",
      "Speed: 2.5ms preprocess, 141.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     445.67       383.4         640      461.21] conf: tensor(0.8489) barcode: [     542.87      420.52      191.66      81.272] conf: tensor(0.9135) value: \n",
      "box: [      79.46      177.58      356.69      262.12] conf: tensor(0.8471) barcode: [     221.99      221.27      267.11      88.006] conf: tensor(0.9497) value: Hii Sir\n",
      "box: [      79.46      177.58      356.69      262.12] conf: tensor(0.8471) barcode: [     530.45      208.57      218.05      83.024] conf: tensor(0.9492) value: \n",
      "box: [      79.46      177.58      356.69      262.12] conf: tensor(0.8471) barcode: [     240.89      433.97      226.93      73.106] conf: tensor(0.9460) value: \n",
      "box: [      79.46      177.58      356.69      262.12] conf: tensor(0.8471) barcode: [     542.87      420.52      191.66      81.272] conf: tensor(0.9135) value: \n",
      "\n",
      "0: 96x128 3 class_0s, 28.6ms\n",
      "Speed: 0.8ms preprocess, 28.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 147.8ms\n",
      "Speed: 3.9ms preprocess, 147.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     348.96      407.64       613.4      479.08] conf: tensor(0.8442) barcode: [     478.44      444.32      256.04      70.961] conf: tensor(0.9528) value: 1234509876\n",
      "box: [     4.4162      190.27      260.24      269.36] conf: tensor(0.8359) barcode: [     151.19      443.67       210.9      72.591] conf: tensor(0.9662) value: \n",
      "box: [     4.4162      190.27      260.24      269.36] conf: tensor(0.8359) barcode: [     136.59      230.38      240.32      78.552] conf: tensor(0.9609) value: Hii Sir\n",
      "box: [     4.4162      190.27      260.24      269.36] conf: tensor(0.8359) barcode: [     478.44      444.32      256.04      70.961] conf: tensor(0.9528) value: 1234509876\n",
      "box: [     318.38      179.56       585.1      261.48] conf: tensor(0.6805) barcode: [      457.9      222.53      266.37      78.078] conf: tensor(0.9656) value: \n",
      "box: [     318.38      179.56       585.1      261.48] conf: tensor(0.6805) barcode: [     478.44      444.32      256.04      70.961] conf: tensor(0.9528) value: 1234509876\n",
      "\n",
      "0: 96x128 3 class_0s, 27.6ms\n",
      "Speed: 1.2ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 3 class_0s, 153.3ms\n",
      "Speed: 3.0ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [      348.7      189.15      614.78      273.56] conf: tensor(0.8375) barcode: [     480.65      233.96      267.41      82.734] conf: tensor(0.9470) value: \n",
      "box: [      348.7      189.15      614.78      273.56] conf: tensor(0.8375) barcode: [     501.22      450.55      257.69      57.875] conf: tensor(0.8772) value: \n",
      "box: [     50.233      200.07      285.25       280.6] conf: tensor(0.8358) barcode: [     165.18      239.76      235.48      79.311] conf: tensor(0.9479) value: \n",
      "box: [     50.233      200.07      285.25       280.6] conf: tensor(0.8358) barcode: [     480.65      233.96      267.41      82.734] conf: tensor(0.9470) value: \n",
      "box: [     50.233      200.07      285.25       280.6] conf: tensor(0.8358) barcode: [     501.22      450.55      257.69      57.875] conf: tensor(0.8772) value: \n",
      "box: [     369.69       421.7      634.75         480] conf: tensor(0.4610) barcode: [     501.22      450.55      257.69      57.875] conf: tensor(0.8772) value: \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from zxing import BarCodeReader\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def is_rectangle_contained(outer_rect, inner_rect):\n",
    "    outer_x1, outer_y1, outer_x2, outer_y2 = outer_rect\n",
    "    inner_x1, inner_y1, inner_x2, inner_y2 = inner_rect\n",
    "    return inner_x1 >= outer_x1 and inner_y1 >= outer_y1 and inner_x2 <= outer_x2 and inner_y2 <= outer_y2\n",
    "\n",
    "def print_rectangle_contained(results, results2, image):\n",
    "    flag = 0\n",
    "    color1 = (0, 255, 0)  # Green color\n",
    "    color2 = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    reader = BarCodeReader()\n",
    "    \n",
    "    for box in zip(results[0].boxes.xyxy, results[0].boxes.conf):\n",
    "        flag = 0\n",
    "        for box2 in zip(results2[0].boxes.xywh, results2[0].boxes.conf):\n",
    "            if is_rectangle_contained(np.array(box[0]), np.array(box2[0])):\n",
    "                x1, y1, x2, y2 = np.array(box[0])\n",
    "                rect1 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect1[0], rect1[1], color1, thickness)\n",
    "                \n",
    "                x3, y3, width3, height3 = np.array(box2[0])\n",
    "                x, y, width, height = int(x3 - (width3)/2), int(y3 - (height3)/2), int(width3), int(height3)\n",
    "                region_img = image[y:y+height, x:x+width]\n",
    "                region_img_gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Save the cropped region as a temporary file\n",
    "                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "                    temp_file_path = temp_file.name\n",
    "                    cv2.imwrite(temp_file_path, region_img_gray)\n",
    "                \n",
    "                barcode = reader.decode(temp_file_path)\n",
    "                print('box:', np.array(box[0]), 'conf:', box[1], 'barcode:', np.array(box2[0]), 'conf:', box2[1], 'value:', barcode.raw)\n",
    "                flag = 1\n",
    "        \n",
    "        if flag == 0:\n",
    "            x1, y1, x2, y2 = np.array(box[0]) \n",
    "            rect2 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "            cv2.rectangle(image, rect2[0], rect2[1], color2, thickness)\n",
    "            print('box:', np.array(box[0]), 'does not contain barcode')\n",
    "    \n",
    "    cv2.imshow('image', image)\n",
    "\n",
    "# Initialize the trained YOLO model\n",
    "model_trained = YOLO('barcode_scanner.pt')\n",
    "\n",
    "# Open the default camera (usually the built-in webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open camera.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Unable to read frame from camera.\")\n",
    "            break\n",
    "        \n",
    "        # Resize the frame if necessary\n",
    "        # frame_resized = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        # image = frame_resized\n",
    "        \n",
    "        original_height, original_width, _ = frame.shape\n",
    "        \n",
    "        # Perform predictions using your YOLO models\n",
    "        results = model_trained.predict(frame, imgsz=128)\n",
    "        results2 = model_trained.predict(frame, imgsz=(original_height, original_width))\n",
    "        \n",
    "        # Process and display the results\n",
    "        print_rectangle_contained(results, results2, frame)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "        \n",
    "        # Check for 'q' key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the camera and close any open windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8414c03",
   "metadata": {},
   "source": [
    "## image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b03c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 2 class_0s, 43.4ms\n",
      "Speed: 2.0ms preprocess, 43.4ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "WARNING ⚠️ imgsz=[720, 1280] must be multiple of max stride 32, updating to [736, 1280]\n",
      "0: 736x1280 6 class_0s, 842.5ms\n",
      "Speed: 15.7ms preprocess, 842.5ms inference, 3.0ms postprocess per image at shape (1, 3, 736, 1280)\n",
      "box : [     356.55      131.76      761.98      236.09] conf: tensor(0.5574) barcode : [     547.99      187.73      409.76      96.312] conf: tensor(0.9643) value :  \n",
      "box : [     356.55      131.76      761.98      236.09] conf: tensor(0.5574) barcode : [     776.19      327.35      431.51       62.44] conf: tensor(0.9510) value :  \n",
      "box : [     356.55      131.76      761.98      236.09] conf: tensor(0.5574) barcode : [     465.66      619.27      640.69      109.96] conf: tensor(0.8097) value :  \n",
      "box : [     356.55      131.76      761.98      236.09] conf: tensor(0.5574) barcode : [     649.51      602.14      531.49      99.835] conf: tensor(0.3088) value :  \n",
      "box : [     356.55      131.76      761.98      236.09] conf: tensor(0.5574) barcode : [       1033      610.36      72.039      18.942] conf: tensor(0.2513) value :  \n",
      "box : [     161.44      561.98      971.38      664.64] conf: tensor(0.4490) barcode : [     465.66      619.27      640.69      109.96] conf: tensor(0.8097) value :  \n",
      "box : [     161.44      561.98      971.38      664.64] conf: tensor(0.4490) barcode : [     649.51      602.14      531.49      99.835] conf: tensor(0.3088) value :  \n",
      "box : [     161.44      561.98      971.38      664.64] conf: tensor(0.4490) barcode : [       1033      610.36      72.039      18.942] conf: tensor(0.2513) value :  \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from zxing import BarCodeReader\n",
    "import tempfile\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def is_rectangle_contained(outer_rect, inner_rect):\n",
    "    outer_x1, outer_y1, outer_x2, outer_y2 = outer_rect\n",
    "    inner_x1, inner_y1, inner_x2, inner_y2 = inner_rect\n",
    "    return inner_x1 >= outer_x1 and inner_y1 >= outer_y1 and inner_x2 <= outer_x2 and inner_y2 <= outer_y2\n",
    "\n",
    "\n",
    "def print_rectangle_contained(results, results2):\n",
    "    image = results[0].plot() & results2[0].plot()\n",
    "    flag = 0\n",
    "    color1 = (0, 255, 0)  # Green color\n",
    "    color2 = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    reader = BarCodeReader()\n",
    "    for box in zip(results[0].boxes.xyxy, results[0].boxes.conf):\n",
    "        flag = 0\n",
    "        for box2 in zip(results2[0].boxes.xywh, results2[0].boxes.conf):\n",
    "            if is_rectangle_contained(np.array(box[0]), np.array(box2[0])):\n",
    "                x1, y1, x2, y2 = np.array(box[0])\n",
    "                rect1 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect1[0], rect1[1], color1, thickness)\n",
    "                x3, y3, width3, height3 = np.array(box2[0])\n",
    "                x, y, width, height = int(x3 - (width3) / 2), int(y3 - (height3) / 2), int(width3), int(height3)\n",
    "                region_img = image[y:y + height, x:x + width]\n",
    "                region_img_gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "                # Save the cropped region as a temporary file\n",
    "                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "                    temp_file_path = temp_file.name\n",
    "                    cv2.imwrite(temp_file_path, region_img_gray)\n",
    "\n",
    "                # Decode barcode from the temporary file\n",
    "                barcode = reader.decode(temp_file_path)\n",
    "\n",
    "                print('box :', np.array(box[0]), 'conf:', box[1], 'barcode :', np.array(box2[0]), 'conf:', box2[1],\n",
    "                      'value : ', barcode.raw)\n",
    "                flag = 1\n",
    "\n",
    "        if flag == 0:\n",
    "            x1, y1, x2, y2 = np.array(box[0])\n",
    "            rect2 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "            cv2.rectangle(image, rect2[0], rect2[1], color2, thickness)\n",
    "            print('box :', np.array(box[0]), 'does not contain barcode')\n",
    "\n",
    "    cv2.imshow('Detected Barcodes', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Initialize the trained YOLO model\n",
    "model_trained = YOLO('barcode_scanner.pt')\n",
    "\n",
    "# Specify the path to the image file\n",
    "image_path = 'Special_0131.jpg'\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Perform YOLO object detection on the image\n",
    "original_height, original_width, _ = image.shape\n",
    "results = model_trained.predict(image, imgsz=128)\n",
    "results2 = model_trained.predict(image, imgsz=(original_height, original_width))\n",
    "\n",
    "# Print rectangles containing barcodes and decode them\n",
    "print_rectangle_contained(results, results2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225a2e4",
   "metadata": {},
   "source": [
    "## trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ce7ec5",
   "metadata": {},
   "source": [
    "## open camera pyzbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9ff42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ imgsz=[1280, 720] must be multiple of max stride 32, updating to [1280, 736]\n",
      "image 1/1 C:\\Users\\Madhur.Gauri\\Desktop\\COMPUTER _VISION_WORK_\\Read_barcode_code_july\\special_0131.jpg: 416x736 (no detections), 355.4ms\n",
      "Speed: 11.1ms preprocess, 355.4ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 736)\n",
      "No barcodes found in the specified regions.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from pyzbar.pyzbar import decode\n",
    "import matplotlib.pyplot as plt\n",
    "barcode_scanner_model = YOLO('best.pt')\n",
    "\n",
    "\n",
    "def decode_barcodes_from_regions(image, regions):\n",
    "    decoded_barcodes = []\n",
    "    annotated_image = image.copy()  # Create a copy of the original image for annotation\n",
    "    for region in regions:\n",
    "        x, y, width, height = region\n",
    "        # Convert coordinates to integers\n",
    "        x, y, width, height = int(x), int(y), int(width), int(height)\n",
    "        # Crop the region from the image\n",
    "        region_img = image[y:y+height, x:x+width]\n",
    "        # Decode the barcode in the cropped region\n",
    "        detected_barcodes = decode(region_img)\n",
    "        decoded_barcodes.extend(detected_barcodes)\n",
    "        # Draw rectangle around the region\n",
    "        cv2.rectangle(annotated_image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "    return decoded_barcodes, annotated_image\n",
    "\n",
    "def get_box_dimensions(results):\n",
    "    box_dimensions = []\n",
    "    for box, box2 in zip(results[0].boxes.xyxy, results[0].boxes.xywh):\n",
    "        box_dimensions.append([box[0].item(), box[1].item(), box2[2].item(), box2[3].item()])\n",
    "    return box_dimensions\n",
    "\n",
    "# Load the image\n",
    "image_path = 'special_0131.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Load the results from barcode scanner model (assuming you have defined `barcode_scanner_model`)\n",
    "results = barcode_scanner_model.predict(image_path, imgsz=(image.shape[1], image.shape[0]))\n",
    "\n",
    "# Get the box dimensions from the results\n",
    "box_dimensions = get_box_dimensions(results)\n",
    "\n",
    "# Initialize the regions to search for barcodes\n",
    "regions_to_search = []\n",
    "\n",
    "# Fill the regions with box dimensions from results\n",
    "for box_dim in box_dimensions:\n",
    "    x, y, width, height = box_dim\n",
    "    regions_to_search.append((x, y, width, height))\n",
    "\n",
    "# Decode barcodes from the specified regions and get annotated image\n",
    "decoded_barcodes, annotated_image = decode_barcodes_from_regions(image, regions_to_search)\n",
    "\n",
    "# Print the decoded barcodes\n",
    "if decoded_barcodes:\n",
    "    for barcode in decoded_barcodes:\n",
    "        print(f\"Found barcode:\"\n",
    "              f\"\\n Data:    {barcode.data}\"\n",
    "              f\"\\n Type:    {barcode.type}\")\n",
    "else:\n",
    "    print(\"No barcodes found in the specified regions.\")\n",
    "\n",
    "# Display the annotated image\n",
    "plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Annotated Image with Detected Barcodes')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df718e3e",
   "metadata": {},
   "source": [
    "## open camera zxing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d40712a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 (no detections), 53.1ms\n",
      "Speed: 2.0ms preprocess, 53.1ms inference, 1.8ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 338.2ms\n",
      "Speed: 8.2ms preprocess, 338.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.2ms\n",
      "Speed: 0.0ms preprocess, 27.2ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 160.5ms\n",
      "Speed: 6.2ms preprocess, 160.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 0.9ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 160.3ms\n",
      "Speed: 2.0ms preprocess, 160.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 151.5ms\n",
      "Speed: 1.6ms preprocess, 151.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 155.1ms\n",
      "Speed: 2.1ms preprocess, 155.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 29.5ms\n",
      "Speed: 0.5ms preprocess, 29.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 155.0ms\n",
      "Speed: 3.2ms preprocess, 155.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.8ms\n",
      "Speed: 3.1ms preprocess, 26.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 152.5ms\n",
      "Speed: 3.0ms preprocess, 152.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.2ms\n",
      "Speed: 0.8ms preprocess, 26.2ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 140.8ms\n",
      "Speed: 2.8ms preprocess, 140.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.3ms\n",
      "Speed: 0.0ms preprocess, 27.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 146.5ms\n",
      "Speed: 2.0ms preprocess, 146.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 153.7ms\n",
      "Speed: 2.0ms preprocess, 153.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.6ms\n",
      "Speed: 1.2ms preprocess, 24.6ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 152.7ms\n",
      "Speed: 2.0ms preprocess, 152.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.2ms\n",
      "Speed: 2.9ms preprocess, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 143.1ms\n",
      "Speed: 3.3ms preprocess, 143.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 155.2ms\n",
      "Speed: 2.0ms preprocess, 155.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 153.0ms\n",
      "Speed: 2.0ms preprocess, 153.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.7ms\n",
      "Speed: 0.6ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 155.1ms\n",
      "Speed: 2.0ms preprocess, 155.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 147.1ms\n",
      "Speed: 3.2ms preprocess, 147.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 28.9ms\n",
      "Speed: 2.1ms preprocess, 28.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 150.2ms\n",
      "Speed: 3.0ms preprocess, 150.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.1ms\n",
      "Speed: 1.4ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 160.8ms\n",
      "Speed: 1.6ms preprocess, 160.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 139.2ms\n",
      "Speed: 4.0ms preprocess, 139.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.0ms\n",
      "Speed: 1.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 147.4ms\n",
      "Speed: 2.0ms preprocess, 147.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 19.8ms\n",
      "Speed: 1.8ms preprocess, 19.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 142.9ms\n",
      "Speed: 3.5ms preprocess, 142.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 31.3ms\n",
      "Speed: 1.3ms preprocess, 31.3ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 141.4ms\n",
      "Speed: 2.0ms preprocess, 141.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 28.3ms\n",
      "Speed: 1.5ms preprocess, 28.3ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 142.9ms\n",
      "Speed: 2.0ms preprocess, 142.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.6ms\n",
      "Speed: 3.0ms preprocess, 27.6ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 148.6ms\n",
      "Speed: 2.6ms preprocess, 148.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.6ms\n",
      "Speed: 1.0ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 143.4ms\n",
      "Speed: 3.4ms preprocess, 143.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 28.3ms\n",
      "Speed: 0.5ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 257.2ms\n",
      "Speed: 3.0ms preprocess, 257.2ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 41.9ms\n",
      "Speed: 3.2ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 285.9ms\n",
      "Speed: 4.0ms preprocess, 285.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 42.9ms\n",
      "Speed: 1.0ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 275.5ms\n",
      "Speed: 4.1ms preprocess, 275.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 40.8ms\n",
      "Speed: 2.9ms preprocess, 40.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 1 class_0, 277.2ms\n",
      "Speed: 5.7ms preprocess, 277.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 46.3ms\n",
      "Speed: 2.3ms preprocess, 46.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 1 class_0, 277.6ms\n",
      "Speed: 4.3ms preprocess, 277.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 41.9ms\n",
      "Speed: 2.1ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 3 class_0s, 301.4ms\n",
      "Speed: 4.0ms preprocess, 301.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 42.9ms\n",
      "Speed: 2.7ms preprocess, 42.9ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 4 class_0s, 273.6ms\n",
      "Speed: 5.2ms preprocess, 273.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 40.2ms\n",
      "Speed: 1.5ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 285.4ms\n",
      "Speed: 3.4ms preprocess, 285.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 50.0ms\n",
      "Speed: 3.0ms preprocess, 50.0ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 277.7ms\n",
      "Speed: 4.5ms preprocess, 277.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 40.2ms\n",
      "Speed: 1.7ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 286.9ms\n",
      "Speed: 5.0ms preprocess, 286.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 40.8ms\n",
      "Speed: 1.5ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 3 class_0s, 275.7ms\n",
      "Speed: 4.3ms preprocess, 275.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 43.2ms\n",
      "Speed: 3.1ms preprocess, 43.2ms inference, 2.3ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 294.9ms\n",
      "Speed: 5.0ms preprocess, 294.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 303.9ms\n",
      "Speed: 5.0ms preprocess, 303.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 40.5ms\n",
      "Speed: 1.2ms preprocess, 40.5ms inference, 2.3ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 200.2ms\n",
      "Speed: 4.0ms preprocess, 200.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 32.9ms\n",
      "Speed: 2.3ms preprocess, 32.9ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 153.5ms\n",
      "Speed: 3.5ms preprocess, 153.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.4ms\n",
      "Speed: 1.0ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 292.3ms\n",
      "Speed: 3.3ms preprocess, 292.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 20.6ms\n",
      "Speed: 2.0ms preprocess, 20.6ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 5 class_0s, 150.7ms\n",
      "Speed: 4.7ms preprocess, 150.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 147.0ms\n",
      "Speed: 2.8ms preprocess, 147.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 21.4ms\n",
      "Speed: 1.3ms preprocess, 21.4ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 144.8ms\n",
      "Speed: 2.0ms preprocess, 144.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.0ms\n",
      "Speed: 2.7ms preprocess, 27.0ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 1 class_0, 152.2ms\n",
      "Speed: 2.6ms preprocess, 152.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 150.3ms\n",
      "Speed: 3.6ms preprocess, 150.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 142.7ms\n",
      "Speed: 4.8ms preprocess, 142.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.1ms\n",
      "Speed: 1.3ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 144.5ms\n",
      "Speed: 2.0ms preprocess, 144.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 44.5ms\n",
      "Speed: 1.9ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 153.9ms\n",
      "Speed: 2.8ms preprocess, 153.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.4ms\n",
      "Speed: 1.1ms preprocess, 25.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 139.0ms\n",
      "Speed: 2.0ms preprocess, 139.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.9ms\n",
      "Speed: 1.0ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 159.4ms\n",
      "Speed: 2.5ms preprocess, 159.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 1 class_0, 28.0ms\n",
      "Speed: 1.4ms preprocess, 28.0ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 149.3ms\n",
      "Speed: 2.9ms preprocess, 149.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     365.06      382.23         640      471.65] conf: tensor(0.5971) barcode: [     501.06      428.58      277.59      84.055] conf: tensor(0.9343) value: \n",
      "\n",
      "0: 96x128 (no detections), 28.2ms\n",
      "Speed: 0.0ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 3 class_0s, 154.4ms\n",
      "Speed: 1.0ms preprocess, 154.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 150.0ms\n",
      "Speed: 1.9ms preprocess, 150.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 0.8ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 151.4ms\n",
      "Speed: 3.0ms preprocess, 151.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 28.8ms\n",
      "Speed: 1.2ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 160.1ms\n",
      "Speed: 2.7ms preprocess, 160.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 30.8ms\n",
      "Speed: 1.0ms preprocess, 30.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 153.3ms\n",
      "Speed: 3.0ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 18.2ms\n",
      "Speed: 2.0ms preprocess, 18.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 141.4ms\n",
      "Speed: 3.1ms preprocess, 141.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.6ms\n",
      "Speed: 1.4ms preprocess, 25.6ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 147.0ms\n",
      "Speed: 3.0ms preprocess, 147.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 143.3ms\n",
      "Speed: 8.5ms preprocess, 143.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 24.8ms\n",
      "Speed: 1.5ms preprocess, 24.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 2 class_0s, 151.3ms\n",
      "Speed: 3.0ms preprocess, 151.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.1ms\n",
      "Speed: 1.3ms preprocess, 26.1ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 171.9ms\n",
      "Speed: 2.0ms preprocess, 171.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 21.4ms\n",
      "Speed: 1.0ms preprocess, 21.4ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 4 class_0s, 148.7ms\n",
      "Speed: 5.5ms preprocess, 148.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 27.2ms\n",
      "Speed: 0.5ms preprocess, 27.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 149.1ms\n",
      "Speed: 2.1ms preprocess, 149.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 20.8ms\n",
      "Speed: 2.5ms preprocess, 20.8ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 140.6ms\n",
      "Speed: 2.8ms preprocess, 140.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 39.7ms\n",
      "Speed: 1.4ms preprocess, 39.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 151.5ms\n",
      "Speed: 1.9ms preprocess, 151.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 32.6ms\n",
      "Speed: 0.5ms preprocess, 32.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 167.3ms\n",
      "Speed: 6.1ms preprocess, 167.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 29.2ms\n",
      "Speed: 1.1ms preprocess, 29.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 159.9ms\n",
      "Speed: 2.9ms preprocess, 159.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 31.3ms\n",
      "Speed: 2.1ms preprocess, 31.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 163.9ms\n",
      "Speed: 2.6ms preprocess, 163.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 33.3ms\n",
      "Speed: 1.0ms preprocess, 33.3ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 175.9ms\n",
      "Speed: 3.4ms preprocess, 175.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 32.0ms\n",
      "Speed: 0.7ms preprocess, 32.0ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 159.8ms\n",
      "Speed: 3.3ms preprocess, 159.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 22.6ms\n",
      "Speed: 3.0ms preprocess, 22.6ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 135.9ms\n",
      "Speed: 2.2ms preprocess, 135.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 3 class_0s, 21.2ms\n",
      "Speed: 1.1ms preprocess, 21.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 146.7ms\n",
      "Speed: 2.0ms preprocess, 146.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     219.15      230.41      560.28      318.13] conf: tensor(0.8539) barcode: [     385.45      276.79      345.99      89.107] conf: tensor(0.9536) value: \n",
      "box: [     219.15      230.41      560.28      318.13] conf: tensor(0.8539) barcode: [     424.78      420.97      237.48      90.627] conf: tensor(0.9410) value: \n",
      "box: [     314.13      378.23      545.43      461.23] conf: tensor(0.7200) barcode: [     424.78      420.97      237.48      90.627] conf: tensor(0.9410) value: \n",
      "box: [      40.93      359.84      266.86      444.17] conf: tensor(0.3073) barcode: [     149.01      400.85      227.32      85.173] conf: tensor(0.9544) value: \n",
      "box: [      40.93      359.84      266.86      444.17] conf: tensor(0.3073) barcode: [     424.78      420.97      237.48      90.627] conf: tensor(0.9410) value: \n",
      "\n",
      "0: 96x128 2 class_0s, 21.9ms\n",
      "Speed: 1.0ms preprocess, 21.9ms inference, 1.8ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 159.8ms\n",
      "Speed: 2.7ms preprocess, 159.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     223.38      246.38      576.55      342.39] conf: tensor(0.8245) barcode: [     396.49      295.35      363.55      91.791] conf: tensor(0.9516) value: \n",
      "box: [     223.38      246.38      576.55      342.39] conf: tensor(0.8245) barcode: [     438.34      438.67      250.87      82.411] conf: tensor(0.9327) value: \n",
      "box: [     35.536      373.94      262.89      465.17] conf: tensor(0.5289) barcode: [     151.51       424.6      231.55      89.512] conf: tensor(0.9524) value: 45653217\n",
      "box: [     35.536      373.94      262.89      465.17] conf: tensor(0.5289) barcode: [     438.34      438.67      250.87      82.411] conf: tensor(0.9327) value: \n",
      "\n",
      "0: 96x128 2 class_0s, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 1.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 150.1ms\n",
      "Speed: 4.7ms preprocess, 150.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     205.55      244.82      577.54      338.74] conf: tensor(0.6480) barcode: [     399.09      292.83      362.68      92.808] conf: tensor(0.9498) value: \n",
      "box: [     205.55      244.82      577.54      338.74] conf: tensor(0.6480) barcode: [      441.5      436.17      250.67      86.347] conf: tensor(0.9448) value: \n",
      "box: [     62.437      244.65      572.27       334.5] conf: tensor(0.3614) barcode: [     109.01      281.59         118      77.028] conf: tensor(0.9523) value: \n",
      "box: [     62.437      244.65      572.27       334.5] conf: tensor(0.3614) barcode: [     155.12      418.37      230.04      89.786] conf: tensor(0.9522) value: \n",
      "box: [     62.437      244.65      572.27       334.5] conf: tensor(0.3614) barcode: [     399.09      292.83      362.68      92.808] conf: tensor(0.9498) value: \n",
      "box: [     62.437      244.65      572.27       334.5] conf: tensor(0.3614) barcode: [      441.5      436.17      250.67      86.347] conf: tensor(0.9448) value: \n",
      "\n",
      "0: 96x128 2 class_0s, 20.5ms\n",
      "Speed: 1.0ms preprocess, 20.5ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 153.3ms\n",
      "Speed: 1.7ms preprocess, 153.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     238.66      389.34      565.85       474.3] conf: tensor(0.3469) barcode: [     438.95      433.31      253.87      90.377] conf: tensor(0.9541) value: \n",
      "box: [     39.455      367.83       268.7      459.23] conf: tensor(0.2636) barcode: [      154.2      412.28      229.19      89.352] conf: tensor(0.9594) value: \n",
      "box: [     39.455      367.83       268.7      459.23] conf: tensor(0.2636) barcode: [     438.95      433.31      253.87      90.377] conf: tensor(0.9541) value: \n",
      "\n",
      "0: 96x128 1 class_0, 25.2ms\n",
      "Speed: 1.0ms preprocess, 25.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 150.0ms\n",
      "Speed: 3.1ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [      274.1      386.95      564.42      473.29] conf: tensor(0.5079) barcode: [     436.78       431.8      251.85      94.036] conf: tensor(0.9634) value: \n",
      "\n",
      "0: 96x128 1 class_0, 31.3ms\n",
      "Speed: 0.9ms preprocess, 31.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 143.5ms\n",
      "Speed: 3.0ms preprocess, 143.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     266.41      387.91       565.2      473.71] conf: tensor(0.5493) barcode: [     438.92      432.16      252.89      92.555] conf: tensor(0.9623) value: \n",
      "\n",
      "0: 96x128 (no detections), 25.1ms\n",
      "Speed: 1.1ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 1 class_0, 146.0ms\n",
      "Speed: 2.5ms preprocess, 146.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 1 class_0, 46.5ms\n",
      "Speed: 1.6ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 147.7ms\n",
      "Speed: 2.8ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [      392.2      367.32      638.56      450.96] conf: tensor(0.3745) barcode: [     514.38      410.03      248.01      78.641] conf: tensor(0.9463) value: \n",
      "\n",
      "0: 96x128 1 class_0, 24.0ms\n",
      "Speed: 1.2ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 146.1ms\n",
      "Speed: 2.0ms preprocess, 146.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [     376.05      367.13      630.85      450.12] conf: tensor(0.3461) barcode: [     487.99      406.76      236.25      77.872] conf: tensor(0.9449) value: \n",
      "\n",
      "0: 96x128 (no detections), 23.9ms\n",
      "Speed: 1.0ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 143.7ms\n",
      "Speed: 3.9ms preprocess, 143.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 20.9ms\n",
      "Speed: 1.4ms preprocess, 20.9ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 150.5ms\n",
      "Speed: 2.0ms preprocess, 150.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 3 class_0s, 145.0ms\n",
      "Speed: 2.0ms preprocess, 145.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 142.4ms\n",
      "Speed: 1.5ms preprocess, 142.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 20.3ms\n",
      "Speed: 0.5ms preprocess, 20.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 140.9ms\n",
      "Speed: 2.5ms preprocess, 140.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 29.8ms\n",
      "Speed: 1.8ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 147.6ms\n",
      "Speed: 2.0ms preprocess, 147.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 17.4ms\n",
      "Speed: 1.0ms preprocess, 17.4ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 147.1ms\n",
      "Speed: 2.0ms preprocess, 147.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 22.3ms\n",
      "Speed: 1.0ms preprocess, 22.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 149.4ms\n",
      "Speed: 3.3ms preprocess, 149.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.7ms\n",
      "Speed: 1.0ms preprocess, 23.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 143.0ms\n",
      "Speed: 2.3ms preprocess, 143.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 32.4ms\n",
      "Speed: 1.4ms preprocess, 32.4ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 141.9ms\n",
      "Speed: 2.0ms preprocess, 141.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 22.2ms\n",
      "Speed: 1.0ms preprocess, 22.2ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 151.5ms\n",
      "Speed: 3.1ms preprocess, 151.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 19.1ms\n",
      "Speed: 0.6ms preprocess, 19.1ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 138.4ms\n",
      "Speed: 3.3ms preprocess, 138.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 1 class_0, 22.2ms\n",
      "Speed: 1.0ms preprocess, 22.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 141.7ms\n",
      "Speed: 4.5ms preprocess, 141.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     322.56      356.64       550.5      440.93] conf: tensor(0.3152) barcode: [     434.62      396.18      237.86      80.879] conf: tensor(0.9535) value: \n",
      "\n",
      "0: 96x128 (no detections), 23.4ms\n",
      "Speed: 1.0ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 146.6ms\n",
      "Speed: 2.3ms preprocess, 146.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.6ms\n",
      "Speed: 2.0ms preprocess, 23.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 144.7ms\n",
      "Speed: 4.3ms preprocess, 144.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 23.5ms\n",
      "Speed: 0.9ms preprocess, 23.5ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 147.9ms\n",
      "Speed: 3.6ms preprocess, 147.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 140.6ms\n",
      "Speed: 2.2ms preprocess, 140.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 1 class_0, 21.0ms\n",
      "Speed: 2.0ms preprocess, 21.0ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 141.7ms\n",
      "Speed: 6.3ms preprocess, 141.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     93.799       339.1      306.08      417.68] conf: tensor(0.5371) barcode: [     196.98      378.09      220.54      73.548] conf: tensor(0.9603) value: \n",
      "box: [     93.799       339.1      306.08      417.68] conf: tensor(0.5371) barcode: [     470.15      381.84      237.21      75.923] conf: tensor(0.9588) value: \n",
      "\n",
      "0: 96x128 2 class_0s, 24.3ms\n",
      "Speed: 2.0ms preprocess, 24.3ms inference, 0.9ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 163.4ms\n",
      "Speed: 4.4ms preprocess, 163.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     359.64      368.98      630.02      457.13] conf: tensor(0.6633) barcode: [     489.18      413.75       246.3      88.737] conf: tensor(0.9467) value: \n",
      "box: [     280.34      218.29      637.03      306.54] conf: tensor(0.6438) barcode: [     489.18      413.75       246.3      88.737] conf: tensor(0.9467) value: \n",
      "box: [     280.34      218.29      637.03      306.54] conf: tensor(0.6438) barcode: [     451.52      262.43       370.8       84.25] conf: tensor(0.9384) value: \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from zxing import BarCodeReader\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def is_rectangle_contained(outer_rect, inner_rect):\n",
    "    outer_x1, outer_y1, outer_x2, outer_y2 = outer_rect\n",
    "    inner_x1, inner_y1, inner_x2, inner_y2 = inner_rect\n",
    "    return inner_x1 >= outer_x1 and inner_y1 >= outer_y1 and inner_x2 <= outer_x2 and inner_y2 <= outer_y2\n",
    "\n",
    "def print_rectangle_contained(results, results2, image):\n",
    "    flag = 0\n",
    "    color1 = (0, 255, 0)  # Green color\n",
    "    color2 = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    reader = BarCodeReader()\n",
    "    \n",
    "    for box in zip(results[0].boxes.xyxy, results[0].boxes.conf):\n",
    "        flag = 0\n",
    "        for box2 in zip(results2[0].boxes.xywh, results2[0].boxes.conf):\n",
    "            if is_rectangle_contained(np.array(box[0]), np.array(box2[0])):\n",
    "                x1, y1, x2, y2 = np.array(box[0])\n",
    "                rect1 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect1[0], rect1[1], color1, thickness)\n",
    "                \n",
    "                x3, y3, width3, height3 = np.array(box2[0])\n",
    "                x, y, width, height = int(x3 - (width3)/2), int(y3 - (height3)/2), int(width3), int(height3)\n",
    "                region_img = image[y:y+height, x:x+width]\n",
    "                region_img_gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Save the cropped region as a temporary file\n",
    "                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "                    temp_file_path = temp_file.name\n",
    "                    cv2.imwrite(temp_file_path, region_img_gray)\n",
    "                \n",
    "                barcode = reader.decode(temp_file_path)\n",
    "                print('box:', np.array(box[0]), 'conf:', box[1], 'barcode:', np.array(box2[0]), 'conf:', box2[1], 'value:', barcode.raw)\n",
    "                flag = 1\n",
    "        \n",
    "        if flag == 0:\n",
    "            x1, y1, x2, y2 = np.array(box[0]) \n",
    "            rect2 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "            cv2.rectangle(image, rect2[0], rect2[1], color2, thickness)\n",
    "            print('box:', np.array(box[0]), 'does not contain barcode')\n",
    "    \n",
    "    cv2.imshow('image', image)\n",
    "\n",
    "# Initialize the trained YOLO model\n",
    "model_trained = YOLO('barcode_scanner.pt')\n",
    "\n",
    "# Open the default camera (usually the built-in webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open camera.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Unable to read frame from camera.\")\n",
    "            break\n",
    "        \n",
    "        # Resize the frame if necessary\n",
    "        # frame_resized = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        # image = frame_resized\n",
    "        \n",
    "        original_height, original_width, _ = frame.shape\n",
    "        \n",
    "        # Perform predictions using your YOLO models\n",
    "        results = model_trained.predict(frame, imgsz=128)\n",
    "        results2 = model_trained.predict(frame, imgsz=(original_height, original_width))\n",
    "        \n",
    "        # Process and display the results\n",
    "        print_rectangle_contained(results, results2, frame)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "        \n",
    "        # Check for 'q' key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the camera and close any open windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc3e9e",
   "metadata": {},
   "source": [
    "## open camera pyzbar different code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602947c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('104000000000388768', 'CODE128'), ('3837404503', 'CODE128'), ('383740450301', 'CODE128'), ('401', 'CODE128')]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "def decode_barcodes(image_path):\n",
    "  \"\"\"Decodes barcodes from an image file.\n",
    "\n",
    "  Args:\n",
    "    image_path: Path to the image file.\n",
    "\n",
    "  Returns:\n",
    "    A list of tuples, where each tuple contains the barcode data and type.\n",
    "  \"\"\"\n",
    "\n",
    "  img = cv2.imread(image_path)\n",
    "  barcodes = decode(img)\n",
    "\n",
    "  barcode_info = []\n",
    "  for barcode in barcodes:\n",
    "    barcode_data = barcode.data.decode('utf-8')\n",
    "    barcode_type = barcode.type\n",
    "    barcode_info.append((barcode_data, barcode_type))\n",
    "\n",
    "  return barcode_info\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'Special_0131.jpg'\n",
    "barcode_data = decode_barcodes(image_path)\n",
    "print(barcode_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652eb25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'data': '104000000000388768', 'type': 'CODE128'}, {'data': '3837404503', 'type': 'CODE128'}, {'data': '383740450301', 'type': 'CODE128'}, {'data': '401', 'type': 'CODE128'}]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "def decode_barcodes(image_path):\n",
    "  img = cv2.imread(image_path)\n",
    "\n",
    "  # Preprocessing (optional):\n",
    "  # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "  # _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)  # Apply thresholding\n",
    "\n",
    "  barcodes = decode(img)\n",
    "\n",
    "  barcode_data = []\n",
    "  for barcode in barcodes:\n",
    "    barcode_info = {\n",
    "      'data': barcode.data.decode('utf-8'),\n",
    "      'type': barcode.type\n",
    "    }\n",
    "    barcode_data.append(barcode_info)\n",
    "\n",
    "  return barcode_data\n",
    "\n",
    "# Example usage:\n",
    "image_path = 'Special_0131.jpg'\n",
    "barcode_data = decode_barcodes(image_path)\n",
    "print(barcode_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d121a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "def decode_barcodes_from_camera():\n",
    "    cap = cv2.VideoCapture(0)  # Access the default camera\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        barcodes = decode(frame)\n",
    "\n",
    "        for barcode in barcodes:\n",
    "            barcode_data = barcode.data.decode('utf-8')\n",
    "            barcode_type = barcode.type\n",
    "            print(f\"Barcode Data: {barcode_data}, Type: {barcode_type}\")\n",
    "\n",
    "        cv2.imshow('Barcode Scanner', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    decode_barcodes_from_camera()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d36cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zxing"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\madhur.gauri\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\madhur.gauri\\appdata\\local\\anaconda3\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading zxing-1.0.3.tar.gz (689 kB)\n",
      "     ---------------------------------------- 0.0/689.6 kB ? eta -:--:--\n",
      "     ---- ---------------------------------- 71.7/689.6 kB 2.0 MB/s eta 0:00:01\n",
      "     ------ ------------------------------- 112.6/689.6 kB 1.3 MB/s eta 0:00:01\n",
      "     -------- ----------------------------- 153.6/689.6 kB 1.1 MB/s eta 0:00:01\n",
      "     ---------- --------------------------- 194.6/689.6 kB 1.2 MB/s eta 0:00:01\n",
      "     --------------- ---------------------- 276.5/689.6 kB 1.2 MB/s eta 0:00:01\n",
      "     ------------------ ------------------- 337.9/689.6 kB 1.3 MB/s eta 0:00:01\n",
      "     ----------------------- -------------- 430.1/689.6 kB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 522.2/689.6 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------  686.1/689.6 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 689.6/689.6 kB 1.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: zxing\n",
      "  Building wheel for zxing (setup.py): started\n",
      "  Building wheel for zxing (setup.py): finished with status 'done'\n",
      "  Created wheel for zxing: filename=zxing-1.0.3-py3-none-any.whl size=684482 sha256=4b1e3481389ff76888a62daa26c94ed86b74e92f0585844fc1616bbd5d4d898a\n",
      "  Stored in directory: c:\\users\\madhur.gauri\\appdata\\local\\pip\\cache\\wheels\\54\\9e\\1d\\bcf402d98d94d79cd20e6d6356428c499271755b68da9aa19e\n",
      "Successfully built zxing\n",
      "Installing collected packages: zxing\n",
      "Successfully installed zxing-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install zxing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a559386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 (no detections), 126.9ms\n",
      "Speed: 8.1ms preprocess, 126.9ms inference, 6.8ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 515.7ms\n",
      "Speed: 5.7ms preprocess, 515.7ms inference, 11.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 43.6ms\n",
      "Speed: 3.6ms preprocess, 43.6ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 232.0ms\n",
      "Speed: 11.6ms preprocess, 232.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 44.2ms\n",
      "Speed: 6.4ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 240.2ms\n",
      "Speed: 3.7ms preprocess, 240.2ms inference, 25.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 45.3ms\n",
      "Speed: 2.6ms preprocess, 45.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 242.5ms\n",
      "Speed: 5.4ms preprocess, 242.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 34.0ms\n",
      "Speed: 18.5ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 289.7ms\n",
      "Speed: 2.0ms preprocess, 289.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 51.4ms\n",
      "Speed: 9.9ms preprocess, 51.4ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 254.3ms\n",
      "Speed: 8.6ms preprocess, 254.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 45.6ms\n",
      "Speed: 1.9ms preprocess, 45.6ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 358.3ms\n",
      "Speed: 7.9ms preprocess, 358.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 35.2ms\n",
      "Speed: 8.5ms preprocess, 35.2ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 302.8ms\n",
      "Speed: 2.5ms preprocess, 302.8ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 46.8ms\n",
      "Speed: 6.7ms preprocess, 46.8ms inference, 3.9ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 260.3ms\n",
      "Speed: 7.0ms preprocess, 260.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 42.5ms\n",
      "Speed: 7.1ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 204.2ms\n",
      "Speed: 5.5ms preprocess, 204.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 1 class_0, 53.6ms\n",
      "Speed: 6.0ms preprocess, 53.6ms inference, 2.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 396.5ms\n",
      "Speed: 5.1ms preprocess, 396.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [     165.33      314.87      584.06      387.22] conf: tensor(0.3347) barcode: [     215.58      345.69      87.463      59.046] conf: tensor(0.9512) value: \n",
      "box: [     165.33      314.87      584.06      387.22] conf: tensor(0.3347) barcode: [     439.62      353.01      279.06      69.865] conf: tensor(0.9491) value: \n",
      "box: [     165.33      314.87      584.06      387.22] conf: tensor(0.3347) barcode: [     246.16      450.27      181.31      59.459] conf: tensor(0.9305) value: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 1 class_0, 86.3ms\n",
      "Speed: 6.5ms preprocess, 86.3ms inference, 3.3ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [     165.33      314.87      584.06      387.22] conf: tensor(0.3347) barcode: [     476.65      458.47      210.07      43.051] conf: tensor(0.9027) value: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 class_0s, 461.5ms\n",
      "Speed: 7.7ms preprocess, 461.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [     147.17      359.35      639.64      466.82] conf: tensor(0.7235) barcode: [     489.38      414.89      300.31      91.644] conf: tensor(0.9648) value: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 1 class_0, 118.9ms\n",
      "Speed: 3.2ms preprocess, 118.9ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [     147.17      359.35      639.64      466.82] conf: tensor(0.7235) barcode: [     217.13      404.35      128.74      84.152] conf: tensor(0.9551) value: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 class_0s, 576.7ms\n",
      "Speed: 6.9ms preprocess, 576.7ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [     165.82      364.48         640      455.11] conf: tensor(0.7014) barcode: [     488.11      410.54      303.79      78.844] conf: tensor(0.9548) value: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 (no detections), 53.7ms\n",
      "Speed: 4.0ms preprocess, 53.7ms inference, 2.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box: [     165.82      364.48         640      455.11] conf: tensor(0.7014) barcode: [      226.6      404.18      118.33      73.179] conf: tensor(0.9524) value: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 499.7ms\n",
      "Speed: 9.9ms preprocess, 499.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 70.4ms\n",
      "Speed: 2.0ms preprocess, 70.4ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 395.5ms\n",
      "Speed: 6.6ms preprocess, 395.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 74.1ms\n",
      "Speed: 2.0ms preprocess, 74.1ms inference, 1.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 424.9ms\n",
      "Speed: 14.4ms preprocess, 424.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 55.8ms\n",
      "Speed: 2.1ms preprocess, 55.8ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 382.4ms\n",
      "Speed: 8.2ms preprocess, 382.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 53.6ms\n",
      "Speed: 1.7ms preprocess, 53.6ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 453.4ms\n",
      "Speed: 14.1ms preprocess, 453.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 96.2ms\n",
      "Speed: 1.3ms preprocess, 96.2ms inference, 1.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 561.2ms\n",
      "Speed: 5.1ms preprocess, 561.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 166.3ms\n",
      "Speed: 16.9ms preprocess, 166.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 673.9ms\n",
      "Speed: 11.4ms preprocess, 673.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 156.0ms\n",
      "Speed: 5.4ms preprocess, 156.0ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 539.4ms\n",
      "Speed: 19.5ms preprocess, 539.4ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 67.9ms\n",
      "Speed: 3.0ms preprocess, 67.9ms inference, 2.2ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 512.7ms\n",
      "Speed: 6.2ms preprocess, 512.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 58.5ms\n",
      "Speed: 2.3ms preprocess, 58.5ms inference, 2.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 394.8ms\n",
      "Speed: 12.4ms preprocess, 394.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 47.0ms\n",
      "Speed: 3.4ms preprocess, 47.0ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 410.1ms\n",
      "Speed: 5.3ms preprocess, 410.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 49.2ms\n",
      "Speed: 2.3ms preprocess, 49.2ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 384.0ms\n",
      "Speed: 6.6ms preprocess, 384.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 64.5ms\n",
      "Speed: 6.3ms preprocess, 64.5ms inference, 1.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 407.8ms\n",
      "Speed: 9.5ms preprocess, 407.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 57.0ms\n",
      "Speed: 2.1ms preprocess, 57.0ms inference, 0.9ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 390.0ms\n",
      "Speed: 6.4ms preprocess, 390.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 55.3ms\n",
      "Speed: 3.3ms preprocess, 55.3ms inference, 0.9ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 389.9ms\n",
      "Speed: 7.9ms preprocess, 389.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 52.8ms\n",
      "Speed: 2.3ms preprocess, 52.8ms inference, 1.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 (no detections), 391.8ms\n",
      "Speed: 5.9ms preprocess, 391.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 56.3ms\n",
      "Speed: 3.5ms preprocess, 56.3ms inference, 1.8ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from zxing import BarCodeReader\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def is_rectangle_contained(outer_rect, inner_rect):\n",
    "    outer_x1, outer_y1, outer_x2, outer_y2 = outer_rect\n",
    "    inner_x1, inner_y1, inner_x2, inner_y2 = inner_rect\n",
    "    return inner_x1 >= outer_x1 and inner_y1 >= outer_y1 and inner_x2 <= outer_x2 and inner_y2 <= outer_y2\n",
    "\n",
    "def print_rectangle_contained(results, results2, image):\n",
    "    flag = 0\n",
    "    color1 = (0, 255, 0)  # Green color\n",
    "    color2 = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    reader = BarCodeReader()\n",
    "    \n",
    "    for box in zip(results[0].boxes.xyxy, results[0].boxes.conf):\n",
    "        flag = 0\n",
    "        for box2 in zip(results2[0].boxes.xywh, results2[0].boxes.conf):\n",
    "            if is_rectangle_contained(np.array(box[0]), np.array(box2[0])):\n",
    "                x1, y1, x2, y2 = np.array(box[0])\n",
    "                rect1 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect1[0], rect1[1], color1, thickness)\n",
    "                \n",
    "                x3, y3, width3, height3 = np.array(box2[0])\n",
    "                x, y, width, height = int(x3 - (width3)/2), int(y3 - (height3)/2), int(width3), int(height3)\n",
    "                region_img = image[y:y+height, x:x+width]\n",
    "                region_img_gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Save the cropped region as a temporary file\n",
    "                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "                    temp_file_path = temp_file.name\n",
    "                    cv2.imwrite(temp_file_path, region_img_gray)\n",
    "                \n",
    "                barcode = reader.decode(temp_file_path)\n",
    "                print('box:', np.array(box[0]), 'conf:', box[1], 'barcode:', np.array(box2[0]), 'conf:', box2[1], 'value:', barcode.raw)\n",
    "                flag = 1\n",
    "        \n",
    "        if flag == 0:\n",
    "            x1, y1, x2, y2 = np.array(box[0]) \n",
    "            rect2 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "            cv2.rectangle(image, rect2[0], rect2[1], color2, thickness)\n",
    "            print('box:', np.array(box[0]), 'does not contain barcode')\n",
    "    \n",
    "    cv2.imshow('image', image)\n",
    "\n",
    "# Initialize the trained YOLO model\n",
    "model_trained = YOLO('barcode_scanner.pt')\n",
    "\n",
    "# Open the default camera (usually the built-in webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open camera.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Unable to read frame from camera.\")\n",
    "            break\n",
    "        \n",
    "        # Resize the frame if necessary\n",
    "        # frame_resized = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        # image = frame_resized\n",
    "        \n",
    "        original_height, original_width, _ = frame.shape\n",
    "        \n",
    "        # Perform predictions using your YOLO models\n",
    "        results = model_trained.predict(frame, imgsz=128)\n",
    "        results2 = model_trained.predict(frame, imgsz=(original_height, original_width))\n",
    "        \n",
    "        # Process and display the results\n",
    "        print_rectangle_contained(results, results2, frame)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "        \n",
    "        # Check for 'q' key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the camera and close any open windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6bf56f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m original_height, original_width, _ \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Use trained models for prediction\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m model_trained \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_1.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     90\u001b[0m barcode_scanner_model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarcode_scanner.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     92\u001b[0m results \u001b[38;5;241m=\u001b[39m model_trained\u001b[38;5;241m.\u001b[39mpredict(frame, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mmodel, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\ultralytics\\engine\\model.py:141\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load(model, task\u001b[38;5;241m=\u001b[39mtask)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\ultralytics\\engine\\model.py:230\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    227\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m attempt_load_one_weight(weights)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:790\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m torch_safe_load(weight)  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    791\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    792\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:716\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_modules(\n\u001b[0;32m    710\u001b[0m         {\n\u001b[0;32m    711\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.yolo.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124multralytics.utils\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    714\u001b[0m         }\n\u001b[0;32m    715\u001b[0m     ):  \u001b[38;5;66;03m# for legacy 8.0 Classify and Pose models\u001b[39;00m\n\u001b[1;32m--> 716\u001b[0m         ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(file, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\cvan\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_1.pt'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from zxing import BarCodeReader\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def is_rectangle_contained(outer_rect, inner_rect):\n",
    "    outer_x1, outer_y1, outer_x2, outer_y2 = outer_rect\n",
    "    inner_x1, inner_y1, inner_x2, inner_y2 = inner_rect\n",
    "    return inner_x1 >= outer_x1 and inner_y1 >= outer_y1 and inner_x2 <= outer_x2 and inner_y2 <= outer_y2\n",
    "\n",
    "def print_rectangle_contained(results, results2, decoded_barcodes):\n",
    "    image = results[0].plot() & results2[0].plot()\n",
    "    flag = 0\n",
    "    color1 = (0, 255, 0)  # Green color\n",
    "    color2 = (255, 0, 0)  # Red color\n",
    "    thickness = 2\n",
    "    reader = BarCodeReader()\n",
    "    \n",
    "    for box in zip(results[0].boxes.xyxy, results[0].boxes.conf):\n",
    "        flag = 0\n",
    "        for box2 in zip(results2[0].boxes.xywh, results2[0].boxes.conf):\n",
    "            if is_rectangle_contained(np.array(box[0]), np.array(box2[0])):\n",
    "                x1, y1, x2, y2 = np.array(box[0])\n",
    "                rect1 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect1[0], rect1[1], color1, thickness)\n",
    "                \n",
    "                x3, y3, width3, height3 = np.array(box2[0])\n",
    "                x, y, width, height = int(x3 - (width3) / 2), int(y3 - (height3) / 2), int(width3), int(height3)\n",
    "                region_img = image[y:y + height, x:x + width]\n",
    "                region_img_gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Save the cropped region as a temporary file\n",
    "                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "                    temp_file_path = temp_file.name\n",
    "                    cv2.imwrite(temp_file_path, region_img_gray)\n",
    "                    \n",
    "                barcode = reader.decode(temp_file_path)\n",
    "                \n",
    "                if barcode and barcode.raw not in decoded_barcodes:\n",
    "                    decoded_barcodes.add(barcode.raw)\n",
    "                    print('box :', np.array(box[0]), 'conf:', box[1], 'barcode :', np.array(box2[0]), 'conf:', box2[1], 'value :', barcode.raw)\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    # Clean up the temporary file\n",
    "                    os.remove(temp_file_path)\n",
    "            \n",
    "        if flag == 0:\n",
    "            x1, y1, x2, y2 = np.array(box[0])\n",
    "            rect2 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "            cv2.rectangle(image, rect2[0], rect2[1], color2, thickness)\n",
    "            print('box :', np.array(box[0]), 'does not contain barcode')\n",
    "\n",
    "    cv2.imshow('image', image)\n",
    "\n",
    "# Initialize the trained YOLO model\n",
    "model_trained = YOLO('barcode_scanner.pt')\n",
    "\n",
    "# Specify the path to the video file\n",
    "video_path = 'video.mp4'\n",
    "\n",
    "# Open the video file for reading\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "decoded_barcodes = set()  # Set to keep track of decoded barcodes\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open video.\")\n",
    "else:\n",
    "    # Loop to read and process each frame\n",
    "    while True:\n",
    "        # Read a frame from the video\n",
    "        ret, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        \n",
    "        # Check if the frame was read successfully\n",
    "        if not ret:\n",
    "            print(\"End of video or unable to read frame.\")\n",
    "            break\n",
    "        \n",
    "        if frame_count % 20 != 0:\n",
    "            continue\n",
    "        \n",
    "        image = frame\n",
    "        original_height, original_width, _ = image.shape\n",
    "        \n",
    "        # Use trained models for prediction\n",
    "        model_trained = YOLO('best_1.pt')\n",
    "        barcode_scanner_model = YOLO('barcode_scanner.pt')\n",
    "        \n",
    "        results = model_trained.predict(frame, imgsz=128)\n",
    "        results2 = barcode_scanner_model.predict(frame, imgsz=(original_height, original_width))\n",
    "        print_rectangle_contained(results, results2, decoded_barcodes)\n",
    "        \n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8162f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21d51f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 96x128 1 class_0, 21.0ms\n",
      "Speed: 0.0ms preprocess, 21.0ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 107.8ms\n",
      "Speed: 3.5ms preprocess, 107.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     373.01      47.527      599.22      124.82] does not contain barcode\n",
      "\n",
      "0: 96x128 (no detections), 21.1ms\n",
      "Speed: 0.5ms preprocess, 21.1ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 98.4ms\n",
      "Speed: 2.6ms preprocess, 98.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 14.1ms\n",
      "Speed: 0.8ms preprocess, 14.1ms inference, 1.2ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 92.6ms\n",
      "Speed: 2.8ms preprocess, 92.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 16.7ms\n",
      "Speed: 0.7ms preprocess, 16.7ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 110.7ms\n",
      "Speed: 2.2ms preprocess, 110.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 13.0ms\n",
      "Speed: 0.3ms preprocess, 13.0ms inference, 1.1ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 100.9ms\n",
      "Speed: 1.5ms preprocess, 100.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 14.1ms\n",
      "Speed: 1.0ms preprocess, 14.1ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 99.6ms\n",
      "Speed: 1.9ms preprocess, 99.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 11.5ms\n",
      "Speed: 0.0ms preprocess, 11.5ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 94.0ms\n",
      "Speed: 1.5ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 14.1ms\n",
      "Speed: 0.0ms preprocess, 14.1ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 96.1ms\n",
      "Speed: 1.6ms preprocess, 96.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 15.3ms\n",
      "Speed: 0.0ms preprocess, 15.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 96.0ms\n",
      "Speed: 1.6ms preprocess, 96.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 17.2ms\n",
      "Speed: 0.0ms preprocess, 17.2ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 97.5ms\n",
      "Speed: 1.6ms preprocess, 97.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 14.6ms\n",
      "Speed: 0.0ms preprocess, 14.6ms inference, 0.6ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 93.3ms\n",
      "Speed: 1.5ms preprocess, 93.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 (no detections), 13.8ms\n",
      "Speed: 0.0ms preprocess, 13.8ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 97.1ms\n",
      "Speed: 2.1ms preprocess, 97.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 1 class_0, 13.0ms\n",
      "Speed: 0.0ms preprocess, 13.0ms inference, 0.9ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 99.4ms\n",
      "Speed: 1.5ms preprocess, 99.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box : [      130.6      51.113      375.97       127.1] conf: tensor(0.8606) barcode : [     253.16      90.216      237.34      73.793] conf: tensor(0.9611) value : Hii Sir\n",
      "\n",
      "0: 96x128 1 class_0, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 82.9ms\n",
      "Speed: 1.5ms preprocess, 82.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     436.69      241.92         640      320.19] does not contain barcode\n",
      "\n",
      "0: 96x128 (no detections), 16.5ms\n",
      "Speed: 1.0ms preprocess, 16.5ms inference, 0.5ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 97.9ms\n",
      "Speed: 1.6ms preprocess, 97.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 96x128 1 class_0, 14.3ms\n",
      "Speed: 1.5ms preprocess, 14.3ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 87.9ms\n",
      "Speed: 2.6ms preprocess, 87.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     110.45       58.98      349.13      159.15] does not contain barcode\n",
      "\n",
      "0: 96x128 1 class_0, 12.9ms\n",
      "Speed: 0.0ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 92.9ms\n",
      "Speed: 3.9ms preprocess, 92.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     156.65       51.92      446.88      150.74] does not contain barcode\n",
      "\n",
      "0: 96x128 2 class_0s, 19.3ms\n",
      "Speed: 0.0ms preprocess, 19.3ms inference, 0.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 97.4ms\n",
      "Speed: 2.6ms preprocess, 97.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     192.32      59.634      466.82      160.28] does not contain barcode\n",
      "box: [      543.3      45.716      639.45      135.99] does not contain barcode\n",
      "\n",
      "0: 96x128 3 class_0s, 13.3ms\n",
      "Speed: 1.0ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 86.5ms\n",
      "Speed: 1.6ms preprocess, 86.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     376.01      46.321         640      142.48] does not contain barcode\n",
      "box: [      31.89      51.271      300.22      146.67] does not contain barcode\n",
      "box: [     399.74       308.3         640       396.5] does not contain barcode\n",
      "\n",
      "0: 96x128 4 class_0s, 14.3ms\n",
      "Speed: 1.0ms preprocess, 14.3ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 95.9ms\n",
      "Speed: 1.7ms preprocess, 95.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box : [     354.74      268.21         640      369.25] conf: tensor(0.8902) barcode : [     499.66      321.88      280.68      101.55] conf: tensor(0.9664) value : 1234509876\n",
      "box: [      330.1      3.0034      639.34      97.816] does not contain barcode\n",
      "box: [          0        13.2      258.72      107.78] does not contain barcode\n",
      "box: [     9.0166      255.41      252.61      348.72] does not contain barcode\n",
      "\n",
      "0: 96x128 3 class_0s, 15.7ms\n",
      "Speed: 1.0ms preprocess, 15.7ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 87.1ms\n",
      "Speed: 1.5ms preprocess, 87.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [     326.15      260.86      636.03      369.87] does not contain barcode\n",
      "box: [     306.24      1.7046      639.44       99.08] does not contain barcode\n",
      "box: [          0      9.6323      240.91      101.41] does not contain barcode\n",
      "\n",
      "0: 96x128 3 class_0s, 14.6ms\n",
      "Speed: 1.0ms preprocess, 14.6ms inference, 1.0ms postprocess per image at shape (1, 3, 96, 128)\n",
      "\n",
      "0: 480x640 4 class_0s, 82.2ms\n",
      "Speed: 2.2ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "box: [        340      261.43      639.92      366.47] does not contain barcode\n",
      "box : [     311.37      1.6699         640      99.453] conf: tensor(0.8539) barcode : [     478.26      48.638      321.47      91.591] conf: tensor(0.9645) value : This is Demo,\n",
      "box: [          0      8.2804      248.24      105.62] does not contain barcode\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from zxing import BarCodeReader\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def is_rectangle_contained(outer_rect, inner_rect):\n",
    "    outer_x1, outer_y1, outer_x2, outer_y2 = outer_rect\n",
    "    inner_x1, inner_y1, inner_x2, inner_y2 = inner_rect\n",
    "    return inner_x1 >= outer_x1 and inner_y1 >= outer_y1 and inner_x2 <= outer_x2 and inner_y2 <= outer_y2\n",
    "\n",
    "def print_rectangle_contained(results, results2, image):\n",
    "    flag = 0\n",
    "    color1 = (0, 255, 0)  # Green color\n",
    "    color2 = (255, 0, 0)\n",
    "    thickness = 2\n",
    "    reader = BarCodeReader()\n",
    "    \n",
    "    for box in zip(results[0].boxes.xyxy, results[0].boxes.conf):\n",
    "        flag = 0\n",
    "        for box2 in zip(results2[0].boxes.xywh, results2[0].boxes.conf):\n",
    "            if is_rectangle_contained(np.array(box[0]), np.array(box2[0])):\n",
    "                x1, y1, x2, y2 = np.array(box[0])\n",
    "                rect1 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "                cv2.rectangle(image, rect1[0], rect1[1], color1, thickness)\n",
    "                \n",
    "                x3, y3, width3, height3 = np.array(box2[0])\n",
    "                x, y, width, height = int(x3 - (width3)/2), int(y3 - (height3)/2), int(width3), int(height3)\n",
    "                region_img = image[y:y+height, x:x+width]\n",
    "                region_img_gray = cv2.cvtColor(region_img, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Save the cropped region as a temporary file\n",
    "                with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:\n",
    "                    temp_file_path = temp_file.name\n",
    "                    cv2.imwrite(temp_file_path, region_img_gray)\n",
    "                \n",
    "                barcode = reader.decode(temp_file_path)\n",
    "                \n",
    "                if barcode and barcode.raw not in decoded_barcodes:\n",
    "                    decoded_barcodes.add(barcode.raw)\n",
    "                    print('box :', np.array(box[0]), 'conf:', box[1], 'barcode :', np.array(box2[0]), 'conf:', box2[1], 'value :', barcode.raw)\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    # Clean up the temporary file\n",
    "                    os.remove(temp_file_path)\n",
    "        \n",
    "        if flag == 0:\n",
    "            x1, y1, x2, y2 = np.array(box[0]) \n",
    "            rect2 = ((int(x1), int(y1)), (int(x2), int(y2)))\n",
    "            cv2.rectangle(image, rect2[0], rect2[1], color2, thickness)\n",
    "            print('box:', np.array(box[0]), 'does not contain barcode')\n",
    "    \n",
    "    cv2.imshow('image', image)\n",
    "\n",
    "# Initialize the trained YOLO model\n",
    "model_trained = YOLO('barcode_scanner.pt')\n",
    "\n",
    "# Open the default camera (usually the built-in webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open camera.\")\n",
    "else:\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Unable to read frame from camera.\")\n",
    "            break\n",
    "        \n",
    "        # Resize the frame if necessary\n",
    "        # frame_resized = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)\n",
    "        # image = frame_resized\n",
    "        \n",
    "        original_height, original_width, _ = frame.shape\n",
    "        \n",
    "        # Perform predictions using your YOLO models\n",
    "        results = model_trained.predict(frame, imgsz=128)\n",
    "        results2 = model_trained.predict(frame, imgsz=(original_height, original_width))\n",
    "        \n",
    "        # Process and display the results\n",
    "        print_rectangle_contained(results, results2, frame)\n",
    "        \n",
    "        # Display the frame\n",
    "        cv2.imshow('Live Camera', frame)\n",
    "        \n",
    "        # Check for 'q' key press to exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the camera and close any open windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49845c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: 1234509876 (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: Hii Sir (Type: CODE128)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "def decode_barcodes(frame):\n",
    "    # Decode barcodes in the frame\n",
    "    barcodes = decode(frame)\n",
    "\n",
    "    barcode_data = []\n",
    "    for barcode in barcodes:\n",
    "        # Extract data and type from barcode\n",
    "        barcode_info = {\n",
    "            'data': barcode.data.decode('utf-8'),\n",
    "            'type': barcode.type\n",
    "        }\n",
    "        barcode_data.append(barcode_info)\n",
    "        \n",
    "        # Draw rectangle around detected barcode\n",
    "        (x, y, w, h) = barcode.rect\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Display barcode data on the frame\n",
    "        barcode_text = f\"{barcode_info['data']} ({barcode_info['type']})\"\n",
    "        cv2.putText(frame, barcode_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    return barcode_data\n",
    "\n",
    "def main():\n",
    "    # Open a connection to the camera (0 is typically the default camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access the camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "\n",
    "        # Decode barcodes in the frame\n",
    "        barcode_data = decode_barcodes(frame)\n",
    "        \n",
    "        # Print decoded barcodes data\n",
    "        for data in barcode_data:\n",
    "            print(f\"Decoded barcode data: {data['data']} (Type: {data['type']})\")\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Barcode Scanner', frame)\n",
    "        \n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "331249f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded barcode data: Hii Sir (Type: CODE128)\n",
      "Decoded barcode data: ABCD (Type: CODE128)\n",
      "Decoded barcode data: IJKL (Type: CODE128)\n",
      "Decoded barcode data: EFGH (Type: CODE128)\n",
      "Decoded barcode data: MNOP1234 (Type: CODE128)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "def decode_barcodes(frame, processed_barcodes):\n",
    "    # Decode barcodes in the frame\n",
    "    barcodes = decode(frame)\n",
    "\n",
    "    barcode_data = []\n",
    "    for barcode in barcodes:\n",
    "        # Extract data and type from barcode\n",
    "        barcode_value = barcode.data.decode('utf-8')\n",
    "        barcode_info = {\n",
    "            'data': barcode_value,\n",
    "            'type': barcode.type\n",
    "        }\n",
    "        \n",
    "        # Check if barcode is already processed\n",
    "        if barcode_value not in processed_barcodes:\n",
    "            processed_barcodes.add(barcode_value)\n",
    "            \n",
    "            # Draw rectangle around detected barcode\n",
    "            (x, y, w, h) = barcode.rect\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Display barcode data on the frame\n",
    "            barcode_text = f\"{barcode_info['data']} ({barcode_info['type']})\"\n",
    "            cv2.putText(frame, barcode_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Add barcode data to the list for printing\n",
    "            barcode_data.append(barcode_info)\n",
    "    \n",
    "    return barcode_data\n",
    "\n",
    "def main():\n",
    "    # Open a connection to the camera (0 is typically the default camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access the camera.\")\n",
    "        return\n",
    "    \n",
    "    # Set to keep track of processed barcode values\n",
    "    processed_barcodes = set()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "        \n",
    "        # Decode barcodes in the frame\n",
    "        barcode_data = decode_barcodes(frame, processed_barcodes)\n",
    "        \n",
    "        # Print decoded barcodes data\n",
    "        for data in barcode_data:\n",
    "            print(f\"Decoded barcode data: {data['data']} (Type: {data['type']})\")\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Barcode Scanner', frame)\n",
    "        \n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "def decode_barcodes(frame, processed_barcodes):\n",
    "    # Decode barcodes in the frame\n",
    "    barcodes = decode(frame)\n",
    "\n",
    "    barcode_data = []\n",
    "    for barcode in barcodes:\n",
    "        # Extract data and type from barcode\n",
    "        barcode_value = barcode.data.decode('utf-8')\n",
    "        barcode_info = {\n",
    "            'data': barcode_value,\n",
    "            'type': barcode.type\n",
    "        }\n",
    "        \n",
    "        # Check if barcode is already processed\n",
    "        if barcode_value not in processed_barcodes:\n",
    "            processed_barcodes.add(barcode_value)\n",
    "            \n",
    "            # Draw rectangle around detected barcode\n",
    "            (x, y, w, h) = barcode.rect\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Display barcode data on the frame\n",
    "            barcode_text = f\"{barcode_info['data']} ({barcode_info['type']})\"\n",
    "            cv2.putText(frame, barcode_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Add barcode data to the list for printing\n",
    "            barcode_data.append(barcode_info)\n",
    "    \n",
    "    return barcode_data\n",
    "\n",
    "def main():\n",
    "    # Open a connection to the camera (0 is typically the default camera)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to access the camera.\")\n",
    "        return\n",
    "    \n",
    "    # Set to keep track of processed barcode values\n",
    "    processed_barcodes = set()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to read frame.\")\n",
    "            break\n",
    "        \n",
    "        # Decode barcodes in the frame\n",
    "        barcode_data = decode_barcodes(frame, processed_barcodes)\n",
    "        \n",
    "        # Print decoded barcodes data\n",
    "        for data in barcode_data:\n",
    "            print(f\"Decoded barcode data: {data['data']} (Type: {data['type']})\")\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Barcode Scanner', frame)\n",
    "        \n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae64688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded barcode data: 849520 (Type: I25)\n",
      "Video stream ended or error occurred.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from pyzbar.pyzbar import decode\n",
    "\n",
    "def decode_barcodes(frame, processed_barcodes):\n",
    "    # Decode barcodes in the frame\n",
    "    barcodes = decode(frame)\n",
    "\n",
    "    barcode_data = []\n",
    "    for barcode in barcodes:\n",
    "        # Extract data and type from barcode\n",
    "        barcode_value = barcode.data.decode('utf-8')\n",
    "        barcode_info = {\n",
    "            'data': barcode_value,\n",
    "            'type': barcode.type\n",
    "        }\n",
    "        \n",
    "        # Check if barcode is already processed\n",
    "        if barcode_value not in processed_barcodes:\n",
    "            processed_barcodes.add(barcode_value)\n",
    "            \n",
    "            # Draw rectangle around detected barcode\n",
    "            (x, y, w, h) = barcode.rect\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Display barcode data on the frame\n",
    "            barcode_text = f\"{barcode_info['data']} ({barcode_info['type']})\"\n",
    "            cv2.putText(frame, barcode_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Add barcode data to the list for printing\n",
    "            barcode_data.append(barcode_info)\n",
    "    \n",
    "    return barcode_data\n",
    "\n",
    "def main():\n",
    "    # Path to the video file\n",
    "    video_path = 'video_4.mp4'\n",
    "\n",
    "    # Open a connection to the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Unable to open the video file.\")\n",
    "        return\n",
    "    \n",
    "    # Set to keep track of processed barcode values\n",
    "    processed_barcodes = set()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Video stream ended or error occurred.\")\n",
    "            break\n",
    "        \n",
    "        # Decode barcodes in the frame\n",
    "        barcode_data = decode_barcodes(frame, processed_barcodes)\n",
    "        \n",
    "        # Print decoded barcodes data\n",
    "        for data in barcode_data:\n",
    "            print(f\"Decoded barcode data: {data['data']} (Type: {data['type']})\")\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Barcode Scanner', frame)\n",
    "        \n",
    "        # Exit the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture and close windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea55e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "haan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
